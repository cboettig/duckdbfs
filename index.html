<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content='Provides friendly wrappers for creating duckdb-backed connections
  to tabular datasets (csv, parquet, etc) on local or remote file systems.
  This mimics the behaviour of "open_dataset" in the arrow package, 
  but in addition to S3 file system also generalizes to any list of http URLs.'>
<title>High Performance Remote File System Access Using duckdb • duckdbfs</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="High Performance Remote File System Access Using duckdb">
<meta property="og:description" content='Provides friendly wrappers for creating duckdb-backed connections
  to tabular datasets (csv, parquet, etc) on local or remote file systems.
  This mimics the behaviour of "open_dataset" in the arrow package, 
  but in addition to S3 file system also generalizes to any list of http URLs.'>
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="index.html">duckdbfs</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.3.99</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/cboettig/duckdbfs/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header"><h1 id="duckdbfs">duckdbfs<a class="anchor" aria-label="anchor" href="#duckdbfs"></a>
</h1></div>
<!-- badges: start -->

<p>duckdbfs is a simple wrapper around the <code>duckdb</code> package to facilitate working with the construction of a single lazy table (SQL connection) from a set of file paths, URLs, or S3 URIs.</p>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>You can install the development version of duckdbfs from <a href="https://github.com/" class="external-link">GitHub</a> with:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install.packages("devtools")</span></span>
<span><span class="fu">devtools</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span><span class="st">"cboettig/duckdbfs"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="quickstart">Quickstart<a class="anchor" aria-label="anchor" href="#quickstart"></a>
</h2>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/cboettig/duckdbfs" class="external-link">duckdbfs</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'dplyr'</span></span>
<span><span class="co">#&gt; The following objects are masked from 'package:stats':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     filter, lag</span></span>
<span><span class="co">#&gt; The following objects are masked from 'package:base':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     intersect, setdiff, setequal, union</span></span></code></pre></div>
<p>Imagine we have a collection of URLs to files we want to combine into a single tibble in R. The files could be parquet or csv, and some files may have additional columns not present in other files. The combined data may be very large, potentially bigger than available RAM or slow to download completely, but we may only want a subset using methods like <code><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">dplyr::filter()</a></code> or <code><a href="https://dplyr.tidyverse.org/reference/summarise.html" class="external-link">dplyr::summarise()</a></code>.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">base</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"https://github.com/duckdb/duckdb/raw/main/"</span>,</span>
<span>               <span class="st">"data/parquet-testing/hive-partitioning/union_by_name/"</span><span class="op">)</span></span>
<span><span class="va">f1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">base</span>, <span class="st">"x=1/f1.parquet"</span><span class="op">)</span></span>
<span><span class="va">f2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">base</span>, <span class="st">"x=1/f2.parquet"</span><span class="op">)</span></span>
<span><span class="va">f3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">base</span>, <span class="st">"x=2/f2.parquet"</span><span class="op">)</span></span>
<span><span class="va">urls</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">f1</span>,<span class="va">f2</span>,<span class="va">f3</span><span class="op">)</span></span></code></pre></div>
<p>We can easily access this data without downloading by passing a vector of URLs. Note that if schemas (column names) do not match, we must explicitly request <code>duckdb</code> join the two schemas. Leave this as default, <code>FALSE</code> when not required to achieve much better performance.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/open_dataset.html">open_dataset</a></span><span class="op">(</span><span class="va">urls</span>, unify_schemas <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">ds</span></span>
<span><span class="co">#&gt; # Source:   table&lt;kkkmtknecathhep&gt; [3 x 4]</span></span>
<span><span class="co">#&gt; # Database: DuckDB 0.8.1 [unknown@Linux 6.4.6-76060406-generic:R 4.3.1/:memory:]</span></span>
<span><span class="co">#&gt;       i     j x         k</span></span>
<span><span class="co">#&gt;   &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt;</span></span>
<span><span class="co">#&gt; 1    42    84 1        NA</span></span>
<span><span class="co">#&gt; 2    42    84 1        NA</span></span>
<span><span class="co">#&gt; 3    NA   128 2        33</span></span></code></pre></div>
<p>Use <code><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter()</a></code>, <code><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select()</a></code>, etc from dplyr to subset and process data – <a href="https://dbplyr.tidyverse.org/reference/index.html" class="external-link">any method supported by dbpylr</a>. Then use <code><a href="https://dplyr.tidyverse.org/reference/compute.html" class="external-link">dplyr::collect()</a></code> to trigger evaluation and ingest results of the query into R.</p>
</div>
<div class="section level2">
<h2 id="s3-based-access">S3-based access<a class="anchor" aria-label="anchor" href="#s3-based-access"></a>
</h2>
<p>We can also access remote data over the S3 protocol. An advantage of S3 is that unlike https, it can discover all files in a given folder, so we don’t have to list them individually. This is particularly convenient for accessing large, partitioned datasets, like GBIF: (nearly 200 GB of data split across more than 2000 parquet files)</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">parquet</span> <span class="op">&lt;-</span> <span class="st">"s3://gbif-open-data-us-east-1/occurrence/2023-06-01/occurrence.parquet"</span></span>
<span><span class="fu"><a href="reference/duckdb_s3_config.html">duckdb_s3_config</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">gbif</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/open_dataset.html">open_dataset</a></span><span class="op">(</span><span class="va">parquet</span>, anonymous <span class="op">=</span> <span class="cn">TRUE</span>, s3_region<span class="op">=</span><span class="st">"us-east-1"</span><span class="op">)</span></span></code></pre></div>
<p>The additional configuration arguments are passed to the helper function <code><a href="reference/duckdb_s3_config.html">duckdb_s3_config()</a></code> to set access credentials and configure other settings, like alternative endpoints (for use with S3-compliant systems like <a href="https://min.io" class="external-link">minio</a>). Of course it also possible to set these ahead of time by calling <code><a href="reference/duckdb_s3_config.html">duckdb_s3_config()</a></code> directly. Many of these settings can also be passed along more compactly using the URI query notation found in the <code>arrow</code> package. For instance, we can request anonymous access to a bucket on an alternative endpoint as:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">efi</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/open_dataset.html">open_dataset</a></span><span class="op">(</span><span class="st">"s3://anonymous@neon4cast-scores/parquet/aquatics?endpoint_override=data.ecoforecast.org"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="spatial-data">Spatial data<a class="anchor" aria-label="anchor" href="#spatial-data"></a>
</h2>
<p><code>duckdb</code> can also understand a wide array of spatial data queries for spatial vector data, similar to operations found in the popular <code>sf</code> package. Most spatial query operations require an geometry column that expresses the simple feature geometry in <code>duckdb</code>’s internal geometry format (nearly but not exactly WKB). A common pattern will first generate the geometry column from raw columns, such as <code>latitude</code> and <code>lognitude</code> columns, using the <code>duckdb</code> implementation of the a method familiar to postgis, <code>ST_Point</code>:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spatial_ex</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"https://raw.githubusercontent.com/cboettig/duckdbfs/"</span>,</span>
<span>                     <span class="st">"main/inst/extdata/spatial-test.csv"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/open_dataset.html">open_dataset</a></span><span class="op">(</span>format <span class="op">=</span> <span class="st">"csv"</span><span class="op">)</span> </span>
<span></span>
<span><span class="va">spatial_ex</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>geometry <span class="op">=</span> <span class="fu">ST_Point</span><span class="op">(</span><span class="va">longitude</span>, <span class="va">latitude</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="reference/to_sf.html">to_sf</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; Simple feature collection with 10 features and 3 fields</span></span>
<span><span class="co">#&gt; Geometry type: POINT</span></span>
<span><span class="co">#&gt; Dimension:     XY</span></span>
<span><span class="co">#&gt; Bounding box:  xmin: 1 ymin: 1 xmax: 10 ymax: 10</span></span>
<span><span class="co">#&gt; CRS:           NA</span></span>
<span><span class="co">#&gt;    site latitude longitude      geometry</span></span>
<span><span class="co">#&gt; 1     a        1         1   POINT (1 1)</span></span>
<span><span class="co">#&gt; 2     b        2         2   POINT (2 2)</span></span>
<span><span class="co">#&gt; 3     c        3         3   POINT (3 3)</span></span>
<span><span class="co">#&gt; 4     d        4         4   POINT (4 4)</span></span>
<span><span class="co">#&gt; 5     e        5         5   POINT (5 5)</span></span>
<span><span class="co">#&gt; 6     f        6         6   POINT (6 6)</span></span>
<span><span class="co">#&gt; 7     g        7         7   POINT (7 7)</span></span>
<span><span class="co">#&gt; 8     h        8         8   POINT (8 8)</span></span>
<span><span class="co">#&gt; 9     i        9         9   POINT (9 9)</span></span>
<span><span class="co">#&gt; 10    j       10        10 POINT (10 10)</span></span></code></pre></div>
<p>Recall that when used against any sort of external database like <code>duckdb</code>, most <code>dplyr</code> functions like <code><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">dplyr::mutate()</a></code> are being transcribed into SQL by <code>dbplyr</code>, and not actually ever run in R. This allows us to seamlessly pass along spatial functions like <code>ST_Point</code>, despite this not being an available R function. The <code><a href="reference/to_sf.html">to_sf()</a></code> coercion will parse its input into a SQL query that gets passed to <code>duckdb</code>, and the return object will be collected through <code><a href="https://r-spatial.github.io/sf/reference/st_read.html" class="external-link">sf::st_read</a></code>, returning an (in-memory) <code>sf</code> object.</p>
<p>Note that we can add arbitrary spatial functions that operate on this geometry, provided we do so prior to our call to <code>to_sf</code>. For instance, here we first create our geometry column from lat/lon columns, and then compute the distance from each element to a spatial point:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spatial_ex</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>geometry <span class="op">=</span> <span class="fu">ST_Point</span><span class="op">(</span><span class="va">longitude</span>, <span class="va">latitude</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>dist <span class="op">=</span> <span class="fu">ST_Distance</span><span class="op">(</span><span class="va">geometry</span>, <span class="fu">ST_Point</span><span class="op">(</span><span class="fl">0</span>,<span class="fl">0</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="reference/to_sf.html">to_sf</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; Simple feature collection with 10 features and 4 fields</span></span>
<span><span class="co">#&gt; Geometry type: POINT</span></span>
<span><span class="co">#&gt; Dimension:     XY</span></span>
<span><span class="co">#&gt; Bounding box:  xmin: 1 ymin: 1 xmax: 10 ymax: 10</span></span>
<span><span class="co">#&gt; CRS:           NA</span></span>
<span><span class="co">#&gt;    site latitude longitude      dist      geometry</span></span>
<span><span class="co">#&gt; 1     a        1         1  1.414214   POINT (1 1)</span></span>
<span><span class="co">#&gt; 2     b        2         2  2.828427   POINT (2 2)</span></span>
<span><span class="co">#&gt; 3     c        3         3  4.242641   POINT (3 3)</span></span>
<span><span class="co">#&gt; 4     d        4         4  5.656854   POINT (4 4)</span></span>
<span><span class="co">#&gt; 5     e        5         5  7.071068   POINT (5 5)</span></span>
<span><span class="co">#&gt; 6     f        6         6  8.485281   POINT (6 6)</span></span>
<span><span class="co">#&gt; 7     g        7         7  9.899495   POINT (7 7)</span></span>
<span><span class="co">#&gt; 8     h        8         8 11.313708   POINT (8 8)</span></span>
<span><span class="co">#&gt; 9     i        9         9 12.727922   POINT (9 9)</span></span>
<span><span class="co">#&gt; 10    j       10        10 14.142136 POINT (10 10)</span></span></code></pre></div>
<p>For more details including a complete list of the dozens of spatial operations currently supported and notes on performance and current limitations, see the <a href="https://github.com/duckdb/duckdb_spatial" class="external-link">duckdb spatial docs</a></p>
</div>
<div class="section level2">
<h2 id="writing-datasets">Writing datasets<a class="anchor" aria-label="anchor" href="#writing-datasets"></a>
</h2>
<p>Like <code>arrow::write_dataset()</code>, <code><a href="reference/write_dataset.html">duckdbfs::write_dataset()</a></code> can write partitioned parquet files to local disks and also directly to an S3 bucket. Partitioned writes should take advantage of threading. Partition variables can be specified explicitly, or any <code>dplyr</code> grouping variables will be used by default:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mtcars</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html" class="external-link">group_by</a></span><span class="op">(</span><span class="va">cyl</span>, <span class="va">gear</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="reference/write_dataset.html">write_dataset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="local-files">Local files<a class="anchor" aria-label="anchor" href="#local-files"></a>
</h2>
<p>Of course, <code><a href="reference/open_dataset.html">open_dataset()</a></code> and <code><a href="reference/write_dataset.html">write_dataset()</a></code> also be used with local files. Remember that parquet format is not required, we can read csv files (including multiple and hive-partitioned csv files).</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/write.table.html" class="external-link">write.csv</a></span><span class="op">(</span><span class="va">mtcars</span>, <span class="st">"mtcars.csv"</span>, row.names<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">lazy_cars</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/open_dataset.html">open_dataset</a></span><span class="op">(</span><span class="st">"mtcars.csv"</span>, format <span class="op">=</span> <span class="st">"csv"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="limitations">Limitations<a class="anchor" aria-label="anchor" href="#limitations"></a>
</h2>
<ul>
<li>
<strong><em>NOTE</em></strong>: at this time, the duckdb httpfs file system extension in R does not support Windows.</li>
</ul>
</div>
<div class="section level2">
<h2 id="mechanism--motivation">Mechanism / motivation<a class="anchor" aria-label="anchor" href="#mechanism--motivation"></a>
</h2>
<p>This package simply creates a duckdb connection, ensures the <code>httpfs</code> and <code>spatial</code> extensions are installed if necessary, sets the S3 configuration, and then constructs a <code>VIEW</code> using duckdb’s <code>parquet_scan()</code> or <code>read_csv_auto()</code> methods and associated options. It then returns a <code><a href="https://dplyr.tidyverse.org/reference/tbl.html" class="external-link">dplyr::tbl()</a></code> for the resulting view. Though straightforward, this process is substantially more verbose than the analogous single function call provided by <code>arrow::open_dataset()</code> due mostly to the necessary string manipulation to construct the VIEW as a SQL statement. I’ve used this pattern a lot, especially when arrow is not an option (http data) or has substantially worse performance (many S3 URIs).</p>
</div>
<div class="section level2">
<h2 id="advanced-notes">Advanced notes<a class="anchor" aria-label="anchor" href="#advanced-notes"></a>
</h2>
<p>This is very similar to the behavior of <code>arrow::open_dataset()</code>, with a few exceptions:</p>
<ul>
<li>at this time, <code>arrow</code> does not support access over HTTP – remote sources must be in an S3 or GC-based object store.</li>
<li>With local file system or S3 paths, <code>duckdb</code> can support “globbing” at any point in the path, e.g. <code>open_dataset(data/*/subdir)</code>. (Like arrow, <code><a href="reference/open_dataset.html">duckdbfs::open_dataset</a></code> will assume recursive path discovery on directories). Note that http(s) URLs will always require the full vector since a <code><a href="https://rdrr.io/r/base/ls.html" class="external-link">ls()</a></code> method is not possible. Even with URLs or vector-based paths, <code>duckdb</code> can automatically populate column names given only by hive structure when <code>hive_style=TRUE</code> (default). Note that passing a vector of paths can be significantly faster than globbing with S3 sources where the <code><a href="https://rdrr.io/r/base/ls.html" class="external-link">ls()</a></code> operation is relatively expensive when there are many partitions.</li>
</ul>
</div>
<div class="section level2">
<h2 id="performance-notes">Performance notes<a class="anchor" aria-label="anchor" href="#performance-notes"></a>
</h2>
<ul>
<li>In some settings, <code><a href="reference/open_dataset.html">duckdbfs::open_dataset</a></code> can give substantially better performance (orders of magnitude) than <code>arrow::open_dataset()</code>, while in other settings it may be comparable or even slower. Package versions, system libraries, network architecture, remote storage performance, network traffic, and other factors can all influence performance, making precise benchmark comparisons in real-world contexts difficult.</li>
<li>On slow network connections or when accessing a remote table repeatedly, it may improve performance to create a local copy of the table rather than perform all operations over the network. The simplest way to do this is by setting the <code>mode = "TABLE"</code> instead of “VIEW” on open dataset. It is probably desirable to pass a duckdb connection backed by persistent disk location in this case instead of the default <code><a href="reference/cached_connection.html">cached_connection()</a></code> unless available RAM is not limiting.</li>
<li>
<code>unify_schema</code> is very computationally expensive. Ensuring all files/partitions match schema in advance or processing different files separately can greatly improve performance.</li>
</ul>
</div>
</div>
  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://cloud.r-project.org/package=duckdbfs" class="external-link">View on CRAN</a></li>
<li><a href="https://github.com/cboettig/duckdbfs/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/cboettig/duckdbfs/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small><a href="https://opensource.org/licenses/mit-license.php" class="external-link">MIT</a> + file <a href="LICENSE-text.html">LICENSE</a></small></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing duckdbfs</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Carl Boettiger <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0002-1642-628X" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
</ul>
</div>

<div class="dev-status">
<h2 data-toc-skip>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/cboettig/duckdbfs/actions/workflows/R-CMD-check.yaml" class="external-link"><img src="https://github.com/cboettig/duckdbfs/actions/workflows/R-CMD-check.yaml/badge.svg" alt="R-CMD-check"></a></li>
</ul>
</div>

  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Carl Boettiger.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
